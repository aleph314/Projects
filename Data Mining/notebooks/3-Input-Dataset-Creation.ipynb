{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fraud Detection Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Previous Notebooks\n",
    "\n",
    "- [EDA](1-EDA.ipynb)\n",
    "- [Network Analysis](2.1-Network.ipynb)\n",
    "- [Lawyers' Network Analysis](2.2-Network-Lawyers.ipynb)\n",
    "- [Witnesses' Network Analysis](2.3-Network-Witnesses.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Construction\n",
    "\n",
    "In this notebook I create the dataset I will feed into the random forest using the claim score obtained from the network analysis and the following features:\n",
    "\n",
    "- claim filing month\n",
    "- claim profile\n",
    "- province of the accident\n",
    "- difference between accident date and filing date\n",
    "- outgoing money provisions.\n",
    "\n",
    "As possibile target variables I use the company score and a fraud indicator obtained from it by rating a claim as a fraud if the score is greater than 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# claims data\n",
    "claims = pd.read_csv('../data/raw/claims.csv', sep=';', na_values='', keep_default_na=False)\n",
    "claims['filing_date'] = pd.to_datetime(claims['filing_date'])\n",
    "claims['accident_date'] = pd.to_datetime(claims['accident_date'])\n",
    "claims['policy_start_date'] = pd.to_datetime(claims['policy_start_date'])\n",
    "claims['policy_end_date'] = pd.to_datetime(claims['policy_end_date'])\n",
    "# setting index and dropping undesired columns\n",
    "claims.set_index('claim_code', inplace=True)\n",
    "claims.drop(['crash'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "claims.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns derived from claim_profile\n",
    "claims['card'] = claims['claim_profile'].apply(lambda x: 1 if 'CARD' in x else 0)\n",
    "claims['injury'] = claims['claim_profile'].apply(lambda x: 1 if 'L' in x else 0)\n",
    "claims['rca'] = claims['claim_profile'].apply(lambda x: 1 if 'RCA' in x else 0)\n",
    "claims['n_signatures'] = claims['claim_profile'].apply(lambda x: 1 if '1' in x else 2 if '2' in x else 0)\n",
    "# difference between accident and filing + filing month\n",
    "claims['filing_diff'] = (claims['filing_date'] - claims['accident_date']).dt.days\n",
    "claims['filing_month'] = claims['filing_date'].dt.month\n",
    "claims.drop(['filing_date', 'accident_date', 'policy_start_date', 'policy_end_date', 'claim_profile'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding company scoring\n",
    "assessments = pd.read_csv('../data/raw/antifraud_assessments.csv', sep=';')\n",
    "claims = claims.merge(assessments, how='inner', left_index=True, right_on='claim_code').drop(['fraud_evaluation', 'ivass_score'], axis=1).set_index('claim_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding network scores\n",
    "# I'm using 0 to fill missing values because if a claim isn't in the network then it's fair that its score is 0\n",
    "scores = pd.read_pickle('../data/interim/network_scores.pkl')\n",
    "claims = claims.merge(scores, how='left', left_index=True, right_on='claim_code').set_index('claim_code')\n",
    "claims['score'] = claims['score'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding lawyers' network scores\n",
    "# I'm using 0 to fill missing values because if a claim isn't in the network then it's fair that its score is 0\n",
    "scores_legale = pd.read_pickle('../data/interim/lawyers_network_scores.pkl')\n",
    "claims = claims.merge(scores_legale, how='left', left_index=True, right_on='claim_code').set_index('claim_code')\n",
    "claims['lawyer_score'] = claims['lawyer_score'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding witnesses' network scores\n",
    "# I'm using 0 to fill missing values because if a claim isn't in the network then it's fair that its score is 0\n",
    "scores_legale = pd.read_pickle('../data/interim/witnesses_network_scores.pkl')\n",
    "claims = claims.merge(scores_legale, how='left', left_index=True, right_on='claim_code').set_index('claim_code')\n",
    "claims['witness_score'] = claims['witness_score'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding outgoing provisions\n",
    "provisions = pd.read_csv('../data/raw/provisions.csv', sep=';')\n",
    "provisions['total_outgoing_provision'] = provisions['outgoing_forfait_provision'] + provisions['outgoing_provision']\n",
    "claims = claims.merge(provisions, how='left', left_index=True, right_on='claim_code').drop(['incoming_forfait_provision', 'incoming_provision', 'outgoing_forfait_provision', 'outgoing_provision'], axis=1).set_index('claim_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 92583 entries, 2010010000083100 to 2017079430026300\n",
      "Data columns (total 16 columns):\n",
      "black_box                   92583 non-null int64\n",
      "black_box_active            92583 non-null int64\n",
      "accident_province           92583 non-null object\n",
      "n_vehicles                  92583 non-null int64\n",
      "n_people                    92583 non-null int64\n",
      "card                        92583 non-null int64\n",
      "injury                      92583 non-null int64\n",
      "rca                         92583 non-null int64\n",
      "n_signatures                92583 non-null int64\n",
      "filing_diff                 92583 non-null int64\n",
      "filing_month                92583 non-null int64\n",
      "company_score               92511 non-null float64\n",
      "score                       92583 non-null float64\n",
      "lawyer_score                92583 non-null float64\n",
      "witness_score               92583 non-null float64\n",
      "total_outgoing_provision    92316 non-null float64\n",
      "dtypes: float64(5), int64(10), object(1)\n",
      "memory usage: 12.0+ MB\n"
     ]
    }
   ],
   "source": [
    "claims.info() # note to self: should I account for doubled edges? as of now the network cycles algo doesn't check them..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping missing values and adding fraud indicator\n",
    "claims.dropna(inplace=True)\n",
    "claims['fraud_indicator'] = claims['company_score'].apply(lambda x: 1 if x > 50 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "claims.to_pickle('../data/processed/claims.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Following Notebooks\n",
    "\n",
    "- [Random Forest Prediction](4-Model.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
